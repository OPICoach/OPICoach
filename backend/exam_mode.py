# exam_mode.py
import os
import re
import json
from utils import ask_llm, load_prompt_template, feedback_to_score, exam_types
from db_utils.chroma_db_utils import retrieve_random_context, retrieve_related_context
from db_utils.user_db_utils import get_user_info, update_user_progress, save_level_history
from db_utils.exam_db_utils import save_exam_result
from pathlib import Path
import google.cloud.texttospeech as tts
import google.cloud.speech as speech
from datetime import datetime
import pygame
import random

# Google Cloud Speech-to-Text ì„¤ì •
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "./opicoach-e1cb367c0382.json"

#model_name = "gemini-2.5-pro-preview-05-06"
model_name = "gemini-2.0-flash"
PROMPT_MAKEEXAM_FILE = "./prompt/prompt_makeexam.txt"
PROMPT_FEEDBACKS_FILE = "./prompt/prompt_feedbacks.txt"

# Google Cloud Text-to-Speech í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
tts_client = tts.TextToSpeechClient()

async def text_to_speech(text: str, output_path: str):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ MP3 íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        text = text.lower().replace("opic", "ì˜¤í”½").replace("OPIc", "ì˜¤í”½").replace("topic", "í† í”½")
        
        synthesis_input = tts.SynthesisInput(text=text)
        voice = tts.VoiceSelectionParams(
            language_code="en-US",
            name="en-US-Chirp3-HD-Leda"
        )
        audio_config = tts.AudioConfig(
            audio_encoding=tts.AudioEncoding.MP3
        )

        response = tts_client.synthesize_speech(
            input=synthesis_input,
            voice=voice,
            audio_config=audio_config
        )

        with open(output_path, "wb") as out:
            out.write(response.audio_content)
            print(f"ğŸ”Š ìŒì„± íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")
        
        return output_path
    except Exception as e:
        print(f"TTS ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

async def speech_to_text(audio_path: str, _model_name: str = "latest_long") -> str:
    """ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        client = speech.SpeechClient()
        with open(audio_path, "rb") as audio_file:
            content = audio_file.read()

        audio = speech.RecognitionAudio(content=content)
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.MP3,
            sample_rate_hertz=16000,
            language_code="en-US",
            model=_model_name,
            use_enhanced=True,
            speech_contexts=[speech.SpeechContext(phrases=["opic", "opic test"], boost=20.0)]
        )

        response = client.recognize(config=config, audio=audio)
        if response.results:
            transcripts = []
            for result in response.results:
                if result.alternatives:
                    transcripts.append(result.alternatives[0].transcript)
            transcript = " ".join(transcripts)
            print(f"ğŸ“ ì¸ì‹ëœ ìŒì„±: {transcript}")
            return transcript
        else:
            print("ğŸ”‡ ìŒì„±ì´ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return ""
    except Exception as e:
        print(f"STT ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return ""

# ì‹œí—˜ ë¬¸ì œ ìƒì„± í•¨ìˆ˜ (user_pk ë°›ì•„ì„œ ìœ ì € ì •ë³´ í¬í•¨)
async def generate_exam_question(user_pk: int):
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì‹œí—˜ ë¬¸ì œë¥¼ ìƒì„±í•˜ê³  ìŒì„±ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        user_info = get_user_info(user_pk)
        prompt_makeexam_template = await load_prompt_template(PROMPT_MAKEEXAM_FILE)
        context_question = retrieve_random_context("exam_docs", n_results=10)

        prompt_with_user = prompt_makeexam_template.format(
            user_info=user_info_to_str(user_info),
            context=context_question,
            question="",
            answer=""
        )
        question = await ask_llm("", "", context_question, prompt_with_user, __model_name=model_name)
        
        # HTML íƒœê·¸ ì œê±°
        clean_question = question.replace('<br>', ' ').replace('<br/>', ' ').replace('<br />', ' ')
        
        # ë¬¸ì œë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
        audio_dir = Path("audio_files")
        audio_dir.mkdir(exist_ok=True)
        
        # ê¸°ì¡´ íŒŒì¼ë“¤ì—ì„œ ê°€ì¥ í° ë²ˆí˜¸ ì°¾ê¸°
        existing_files = list(audio_dir.glob(f"question_{user_pk}_*.mp3"))
        if existing_files:
            # íŒŒì¼ ì´ë¦„ì—ì„œ ë²ˆí˜¸ ì¶”ì¶œí•˜ê³  ìµœëŒ€ê°’ ì°¾ê¸°
            numbers = [int(f.stem.split('_')[-1]) for f in existing_files]
            next_number = max(numbers) + 1
        else:
            next_number = 1
        
        question_audio_path = f"audio_files/question_{user_pk}_{next_number}.mp3"
        
        await text_to_speech(clean_question, question_audio_path)
        
        print(f"â“ ìƒì„±ëœ ì§ˆë¬¸: {question}")
        return question, question_audio_path
    except Exception as e:
        print(f"ğŸ”¥ generate_exam_question ì˜¤ë¥˜: {e}")
        raise

# ì‹œí—˜ ë¬¸ì œ ìƒì„± í•¨ìˆ˜ (íƒ€ì… í¬í•¨)
async def generate_exam_question(user_pk: int, with_type: bool = False, _model_name: str = "gemini-2.0-flash"):
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì‹œí—˜ ë¬¸ì œë¥¼ ìƒì„±í•˜ê³  ìŒì„±ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        user_info = get_user_info(user_pk)
        prompt_makeexam_template = await load_prompt_template(PROMPT_MAKEEXAM_FILE)

        if with_type:
            # ëœë¤ìœ¼ë¡œ ì‹œí—˜ ìœ í˜• ì„ íƒ
            random_type = random.choice(exam_types)
            exam_template_file = f"./txt_db/exam_templates/{random_type}.txt"
            if not os.path.exists(exam_template_file):
                raise FileNotFoundError(f"ì‹œí—˜ í…œí”Œë¦¿ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {exam_template_file}")
            with open(exam_template_file, 'r', encoding='utf-8') as file:
                context_question = file.read()
        else:
            context_question = retrieve_random_context("exam_docs", n_results=10)

        prompt_with_user = prompt_makeexam_template.format(
            user_info=user_info_to_str(user_info),
            context=context_question,
            question="",
            answer=""
        )
        question = await ask_llm("", "", context_question, prompt_with_user, __model_name=_model_name)
        
        # HTML íƒœê·¸ ì œê±°
        clean_question = question.replace('<br>', ' ').replace('<br/>', ' ').replace('<br />', ' ')
        
        # ë¬¸ì œë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
        audio_dir = Path("audio_files")
        audio_dir.mkdir(exist_ok=True)
        
        # ê¸°ì¡´ íŒŒì¼ë“¤ì—ì„œ ê°€ì¥ í° ë²ˆí˜¸ ì°¾ê¸°
        existing_files = list(audio_dir.glob(f"question_{user_pk}_*.mp3"))
        if existing_files:
            # íŒŒì¼ ì´ë¦„ì—ì„œ ë²ˆí˜¸ ì¶”ì¶œí•˜ê³  ìµœëŒ€ê°’ ì°¾ê¸°
            numbers = [int(f.stem.split('_')[-1]) for f in existing_files]
            next_number = max(numbers) + 1
        else:
            next_number = 1
        
        question_audio_path = f"audio_files/question_{user_pk}_{next_number}.mp3"
        
        await text_to_speech(clean_question, question_audio_path)
        
        print(f"â“ ìƒì„±ëœ ì§ˆë¬¸: {question}")
        if with_type:
            print(f"ğŸ“ ì‹œí—˜ ìœ í˜•: {random_type}")
            return question, question_audio_path, random_type
        return question, question_audio_path
    except Exception as e:
        print(f"ğŸ”¥ generate_exam_question ì˜¤ë¥˜: {e}")
        raise

# ì‹œí—˜ í”¼ë“œë°± ìƒì„± í•¨ìˆ˜ (user_pk ë°›ì•„ì„œ ìœ ì € ì •ë³´ í¬í•¨)
async def generate_exam_feedback(
    question: str,
    user_answer: str,
    user_pk: int,
    question_number: int,
    exam_type: str = "default",
    _model_name: str = "gemini-2.0-flash"
):
    """ì‚¬ìš©ìì˜ ë‹µë³€ì— ëŒ€í•œ í”¼ë“œë°±ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        user_info = get_user_info(user_pk)
        prompt_feedbacks_template = await load_prompt_template(PROMPT_FEEDBACKS_FILE)
        context_feedback = retrieve_related_context(question, user_answer, "exam_docs", n_results=10)

        prompt_with_user = prompt_feedbacks_template.format(
            user_info=user_info_to_str(user_info),
            context=context_feedback,
            question=question,
            answer=user_answer
        )
        
        feedback = await ask_llm(
            question=question,
            answer=user_answer,
            context=context_feedback,
            prompt_template=prompt_with_user,
            __model_name=_model_name
        )
        
        print("\n\033[1;36mğŸ” ì›ë³¸ í”¼ë“œë°± í…ìŠ¤íŠ¸:\033[0m")
        print("="*50)
        print(feedback)
        print("="*50)

        # í”¼ë“œë°± ì ìˆ˜ ê³„ì‚°
        score = await feedback_to_score(feedback, exam_type=exam_type, __model_name="gemini-2.0-flash")
        print(f"\033[1;35mâ­ï¸ í”¼ë“œë°± ì ìˆ˜:\033[0m {score}")

        # ì‚¬ìš©ì ì§„í–‰ë„ ì—…ë°ì´íŠ¸
        progress_result = update_user_progress(user_pk, score)
        if progress_result["status"] == "success":
            print(f"\033[1;32mğŸ“ˆ ì§„í–‰ë„ ì—…ë°ì´íŠ¸ ì™„ë£Œ:\033[0m {progress_result['new_progress']}%")
            
            # ì—…ë°ì´íŠ¸ëœ ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            updated_user_info = get_user_info(user_pk)
            if updated_user_info["status"] == "success":
                current_level = updated_user_info["user"]["past_opic_level"]
                
                # ë ˆë²¨ íˆìŠ¤í† ë¦¬ ì €ì¥
                history_result = save_level_history(user_pk, current_level, score)
                if history_result["status"] == "success":
                    print(f"\033[1;32mğŸ“Š ë ˆë²¨ íˆìŠ¤í† ë¦¬ ì €ì¥ ì™„ë£Œ:\033[0m {current_level} - {score}")

        # DBì— ì €ì¥
        save_exam_result(
            user_pk=user_pk,
            question=question,
            question_audio_path=f"audio_files/question_{user_pk}_{question_number}.mp3",
            user_answer=user_answer,
            user_answer_audio_path=f"audio_files/user_answer_{user_pk}_{question_number}.mp3",
            feedback=feedback,  # ì›ë³¸ ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ì €ì¥
            score=score,  # ì ìˆ˜ ì¶”ê°€
            exam_type=exam_type  # ì‹œí—˜ ìœ í˜• ì¶”ê°€
        )
        
        return {
            "feedback": feedback,  # ì›ë³¸ ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸
            "score": score  # ê³„ì‚°ëœ ì ìˆ˜
        }
    except Exception as e:
        print(f"\033[1;31mğŸ”¥ generate_exam_feedback ì˜¤ë¥˜:\033[0m {e}")
        raise

def user_info_to_str(user_info):
    """
    user_info ë”•ì…”ë„ˆë¦¬ë¥¼ ì‚¬ëŒì´ ì½ê¸° ì¢‹ì€ ë¬¸ìì—´ë¡œ ë³€í™˜.
    í•„ìš”í•œ í•„ë“œë§Œ í¬í•¨í•˜ê±°ë‚˜ í¬ë§· ì¡°ì • ê°€ëŠ¥.
    """
    if not user_info or user_info.get('status') != 'success':
        return "User information not available."
    
    user = user_info.get('user', {})
    fields = ["past_opic_level", "goal_opic_level", "background", "occupation_or_major", "topics_of_interest"]
    info_str = ", ".join(f"{field}: {user.get(field, 'N/A')}" for field in fields)
    return info_str

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ
    import asyncio

    async def test():
        user_pk = 1  # ì˜ˆì‹œ ì‚¬ìš©ì PK
        question, question_audio_path = await generate_exam_question(user_pk)
        print(f"Generated Question: {question}")
        print(f"Generated Audio Path: {question_audio_path}")

        user_answer = "This is a sample answer."  # ì˜ˆì‹œ ë‹µë³€
        feedback = await generate_exam_feedback(question, user_answer, user_pk, 1)
        print(f"Generated Feedback: {feedback}")
    
    async def test_with_type():
        user_pk = 1  # ì˜ˆì‹œ ì‚¬ìš©ì PK
        question, question_audio_path, exam_type = await generate_exam_question(user_pk, with_type=True)
        print(f"Generated Question: {question}")
        print(f"Generated Audio Path: {question_audio_path}")
        print(f"Generated Exam Type: {exam_type}")

        user_answer = "This is a sample answer."
        feedback = await generate_exam_feedback(question, user_answer, user_pk, 1, exam_type=exam_type)
        print(f"Generated Feedback: {feedback}")

    async def test_speech_to_text():
        audio_path = "audio_files/test_2.mp3"
        text = await speech_to_text(audio_path)
        print(f"Generated Text: {text}")

    async def test_generate_exam_feedback():
        import time
        start = time.time()
        print(f"Start time: {start}")

        user_pk = 1  # ì˜ˆì‹œ ì‚¬ìš©ì PK
        question = "Sometimes riding the subway or bus can be uncomfortable. Have you ever had any problems related to transportation? Were there traffic jams, or did something uncomfortable happen? What was the problem, and How did you deal with the situation?"
        audio_path = "audio_files/test_3.mp3"
        user_answer = await speech_to_text(audio_path)
        question_number = 1
        exam_type = "default"
        # model_name = "gemini-2.0-flash"
        # model_name = "gemini-2.5-flash-preview-05-20"
        model_name = "gemini-2.5-pro-preview-05-06"
        feedback = await generate_exam_feedback(
            question=question,
            user_answer=user_answer,
            user_pk=user_pk,
            question_number=question_number,
            exam_type=exam_type,
            _model_name=model_name
        )
        print(f"Generated Feedback: {feedback['feedback']}")
        print(f"Feedback Score: {feedback['score']}")

        end = time.time()
        print(f"End time: {end}")
        print(f"Total time taken: {end - start} seconds")


    # asyncio.run(test())
    # asyncio.run(test_with_type())
    asyncio.run(test_speech_to_text())
    # asyncio.run(test_generate_exam_feedback())
