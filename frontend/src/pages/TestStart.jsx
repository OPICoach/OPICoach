import SideBar from "../components/sideBar/SideBar.jsx";
import { useEffect, useRef, useState } from "react";
import { useRecoilState, useRecoilValue } from "recoil";
import {
  timeLeftState,
  isRunningState,
  audioURLState,
  isRecordingState,
} from "../atom/testAtom.js";
import { userPkState } from "../atom/authAtoms.js";
import axios from "axios";

const TestStart = () => {
  const [currentQuestionIndex, setCurrentQuestionIndex] = useState(0);
  const [currentQuestion, setCurrentQuestion] = useState("");

  const [timeLeft, setTimeLeft] = useRecoilState(timeLeftState);
  const [isRunning, setIsRunning] = useRecoilState(isRunningState);
  const [audioURL, setAudioURL] = useRecoilState(audioURLState);
  const [isRecording, setIsRecording] = useRecoilState(isRecordingState);
  const userPk = useRecoilValue(userPkState);

  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);
  const audioRef = useRef(null);
  const speechSynthesisRef = useRef(window.speechSynthesis);

  // ğŸŸ¡ ì§ˆë¬¸ ë¶ˆëŸ¬ì˜¤ê¸°
  const fetchQuestion = async (index) => {
    try {
      console.log(`ğŸ‘‰ ì§ˆë¬¸ ${index + 1} ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...`);
      const res = await axios.get(`/api/opic/question?index=${index}`);
      if (res.data && res.data.question) {
        console.log("âœ… ì§ˆë¬¸ ë¶ˆëŸ¬ì˜¤ê¸° ì„±ê³µ:", res.data.question);
        setCurrentQuestion(res.data.question);
      } else {
        console.warn("âš ï¸ ì§ˆë¬¸ ì—†ìŒ");
        setCurrentQuestion("");
      }
    } catch (err) {
      console.error("âŒ ì§ˆë¬¸ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨:", err);
      setCurrentQuestion("");
    }
  };

  // ğŸ•’ íƒ€ì´ë¨¸
  useEffect(() => {
    let timer;
    if (isRunning && timeLeft > 0) {
      console.log("â³ íƒ€ì´ë¨¸ ì‹œì‘");
      timer = setInterval(() => {
        setTimeLeft((prev) => prev - 1);
      }, 1000);
    } else if (timeLeft === 0 && isRunning) {
      console.log("ğŸ›‘ íƒ€ì´ë¨¸ ì¢…ë£Œ, ìë™ ë…¹ìŒ ì¢…ë£Œ");
      stopRecording();
    }
    return () => clearInterval(timer);
  }, [isRunning, timeLeft, setTimeLeft]);

  // ğŸ“Œ ì§ˆë¬¸ ì¸ë±ìŠ¤ ë°”ë€” ë•Œë§ˆë‹¤ ìƒˆ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°
  useEffect(() => {
    console.log(`ğŸ”„ ì§ˆë¬¸ ì¸ë±ìŠ¤ ë°”ë€œ: ${currentQuestionIndex}`);
    if (currentQuestionIndex < 1000) {
      fetchQuestion(currentQuestionIndex);
    }
  }, [currentQuestionIndex]);

  // ğŸ¤ ì§ˆë¬¸ í…ìŠ¤íŠ¸ê°€ ì„¸íŒ…ë˜ë©´ ìŒì„± ì½ê³  ë…¹ìŒ ì‹œì‘
  useEffect(() => {
    if (currentQuestionIndex >= 1) {
      console.log("ğŸ‰ ëª¨ë“  ì§ˆë¬¸ ì™„ë£Œ");
      setIsRunning(false);
      alert("ëª¨ë“  ì§ˆë¬¸ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!");
      return;
    }

    if (currentQuestion) {
      console.log("ğŸ“¢ ì§ˆë¬¸ ì½ê³  ë…¹ìŒ ì‹œì‘:", currentQuestion);
      playQuestionAndRecord(currentQuestion);
    }
  }, [currentQuestion, currentQuestionIndex]);

  // ğŸ“¢ ì§ˆë¬¸ ì½ê³  ë…¹ìŒ ì‹œì‘
  const playQuestionAndRecord = (text) => {
    if (!speechSynthesisRef.current) {
      alert("Speech Synthesisë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.");
      return;
    }

    setIsRunning(false);
    setTimeLeft(120);

    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = "ko-KR";

    utterance.onend = () => {
      console.log("ğŸ—£ï¸ ì§ˆë¬¸ ì½ê¸° ì™„ë£Œ");
      startRecording();
      setIsRunning(true);
    };

    console.log("ğŸ—£ï¸ ì§ˆë¬¸ ì½ê¸° ì‹œì‘:", text);
    speechSynthesisRef.current.cancel();
    speechSynthesisRef.current.speak(utterance);
  };

  // ğŸ™ï¸ ë…¹ìŒ ì‹œì‘
  const startRecording = async () => {
    try {
      console.log("ğŸ™ï¸ ë…¹ìŒ ì‹œì‘ ìš”ì²­");
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        audioChunksRef.current.push(event.data);
      };

      mediaRecorder.onstop = () => {
        console.log("ğŸ›‘ ë…¹ìŒ ì¤‘ì§€, Blob ìƒì„± ë° ì—…ë¡œë“œ ì‹œì‘");
        const audioBlob = new Blob(audioChunksRef.current, { type: "audio/wav" });
        const audioUrl = URL.createObjectURL(audioBlob);
        setAudioURL(audioUrl);
        uploadAudio(audioBlob);
      };

      mediaRecorder.start();
      setIsRecording(true);
      console.log("âœ… ë…¹ìŒ ì‹œì‘ë¨");
    } catch (err) {
      console.error("âŒ ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:", err);
      alert("ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.");
    }
  };

  // ğŸ›‘ ë…¹ìŒ ì¤‘ì§€ + ë‹¤ìŒ ì§ˆë¬¸
  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      console.log("ğŸ›‘ ë…¹ìŒ ì¤‘ì§€ ìš”ì²­");
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      mediaRecorderRef.current.stream.getTracks().forEach((track) => track.stop());
      setIsRunning(false);
      setTimeLeft(0);
      setCurrentQuestionIndex((prev) => prev + 1);
    }
  };

  // â¬†ï¸ ì˜¤ë””ì˜¤ ì—…ë¡œë“œ
  const uploadAudio = async (audioBlob) => {
    if (!userPk) {
      console.warn("â— userPk ì—†ìŒ");
      return;
    }

    const formData = new FormData();
    formData.append("userPk", userPk);
    formData.append("audio", audioBlob, `recording_question_${currentQuestionIndex + 1}.wav`);
    formData.append("duration", 120 - timeLeft);
    formData.append("question", currentQuestion);

    try {
      const response = await axios.post("/api/audio/upload", formData, {
        headers: { "Content-Type": "multipart/form-data" },
      });
      console.log("â¬†ï¸ ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ì„±ê³µ:", response.data);
    } catch (error) {
      console.error("âŒ ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ì‹¤íŒ¨:", error);
    }
  };

  // â–¶ï¸ ì˜¤ë””ì˜¤ ì¬ìƒ
  const handlePlayAudio = () => {
    if (audioRef.current) {
      console.log("â–¶ï¸ ì˜¤ë””ì˜¤ ì¬ìƒ");
      audioRef.current.play();
    }
  };

  // â±ï¸ íƒ€ì´ë¨¸ í¬ë§·
  const formatTime = (seconds) => {
    const m = Math.floor(seconds / 60).toString().padStart(2, "0");
    const s = (seconds % 60).toString().padStart(2, "0");
    return `${m}:${s}`;
  };

  return (
    <div className="flex flex-row">
      <SideBar />
      <div className="flex flex-col justify-center items-center w-full h-screen bg-white p-6">
        <div className="mb-8 text-2xl font-bold">
          ì§ˆë¬¸ {currentQuestionIndex + 1} /
        </div>
        <div className="w-[280px] h-[280px] border-4 border-primary rounded-full flex items-center justify-center text-5xl font-bold text-black">
          {formatTime(timeLeft)}
        </div>

        <div className="flex gap-6 mt-8">
          <button
            onClick={() => {
              if (!isRunning && !isRecording && currentQuestion) {
                console.log("ğŸ” ë‹¤ì‹œ ì‹œì‘ í´ë¦­");
                playQuestionAndRecord(currentQuestion);
              }
            }}
            disabled={isRunning || isRecording || !currentQuestion}
            className={`px-6 py-3 rounded-lg text-white ${
              isRunning || isRecording || !currentQuestion
                ? "bg-gray-300 cursor-not-allowed"
                : "bg-primary hover:bg-blue-600"
            }`}
          >
            {currentQuestion ? "ë‹¤ì‹œ ì‹œì‘" : "ë"}
          </button>

          <button
            onClick={handlePlayAudio}
            disabled={!audioURL}
            className={`px-6 py-3 rounded-lg ${
              audioURL
                ? "bg-green-500 text-white hover:bg-green-600"
                : "bg-gray-300 text-gray-500 cursor-not-allowed"
            }`}
          >
            ë‹µë³€ ì¬ìƒ
          </button>
        </div>

        {audioURL && <audio ref={audioRef} src={audioURL} className="hidden" />}
      </div>
    </div>
  );
};

export default TestStart;
